{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FSRCNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTG4F3RwYRuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWoOL3InQ8yG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q drive/My\\ Drive/dataset/image/anime.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRCKxStqRyV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, random\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torchvision as tv\n",
        "import numpy as np\n",
        "from PIL import Image, ImageFilter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uMbq7inR1oy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FSRCNN(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(FSRCNN, self).__init__()\n",
        "        self.first_part = self.__first()\n",
        "        self.mid_part = self.__mid()\n",
        "        self.last_part = self.__last()\n",
        "    \n",
        "    def __first(self):\n",
        "        first = nn.Sequential()\n",
        "        first.add_module('first_conv1', nn.Conv2d(1, 32, kernel_size=3, padding=1))\n",
        "        first.add_module('first_prelu1', nn.PReLU())\n",
        "        first.add_module('first_conv2', nn.Conv2d(32, 32, kernel_size=3, padding=1))\n",
        "        first.add_module('first_prelu2', nn.PReLU())\n",
        "        first.add_module('first_conv3', nn.Conv2d(32, 64, kernel_size=3, padding=1))\n",
        "        first.add_module('first_prelu3', nn.PReLU())\n",
        "        first.add_module('first_conv4', nn.Conv2d(64, 64, kernel_size=3, padding=1))\n",
        "        first.add_module('first_prelu4', nn.PReLU())\n",
        "        for m in first.modules():\n",
        "            if type(m) is nn.Conv2d:\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "        return first\n",
        "    \n",
        "    def __mid(self):\n",
        "        mid = nn.Sequential()\n",
        "        mid.add_module('mid_conv1', nn.Conv2d(64, 16, kernel_size=1))\n",
        "        mid.add_module('mid_prelu1', nn.PReLU())\n",
        "        for i in range(4):\n",
        "            mid.add_module(f'mid_conv{i+2}', nn.Conv2d(16, 16, kernel_size=3, padding=1))\n",
        "        mid.add_module('mid_conv6', nn.Conv2d(16, 64, kernel_size=1))\n",
        "        mid.add_module('mid_prelu2', nn.PReLU())\n",
        "        for m in mid.modules():\n",
        "            if type(m) is nn.Conv2d:\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "        return mid\n",
        "    \n",
        "    def __last(self):\n",
        "        last = nn.ConvTranspose2d(64, 1, kernel_size=9, padding=4, stride=2, output_padding=1)\n",
        "        nn.init.kaiming_normal_(last.weight)\n",
        "        return last\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.first_part(x)\n",
        "        x = self.mid_part(x)\n",
        "        x = self.last_part(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaGc2_GXR4H9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SuperResolutionDataset(Dataset):\n",
        "    def __init__(self, path, blur=False):\n",
        "        self.path = path\n",
        "        self.n_samples = len(list(os.walk(path))[0][2])\n",
        "        self.preprocess = tv.transforms.Compose([\n",
        "            tv.transforms.ToPILImage(),\n",
        "            tv.transforms.RandomCrop(224),\n",
        "            tv.transforms.RandomHorizontalFlip(),\n",
        "            tv.transforms.RandomVerticalFlip()\n",
        "        ])\n",
        "        self.downscale = tv.transforms.Resize(112)\n",
        "        self.totensor = tv.transforms.ToTensor()\n",
        "        self.blur = blur\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        I = cv2.imread(os.path.join(self.path, f'img_{idx}.png'))\n",
        "        y = cv2.split(cv2.cvtColor(I, cv2.COLOR_BGR2YCrCb))[0]\n",
        "        I = self.preprocess(y)\n",
        "        image = self.downscale(I)\n",
        "        if self.blur and random.random() > .5:\n",
        "            image = image.filter(ImageFilter.GaussianBlur(radius=1))\n",
        "        I = self.totensor(I)\n",
        "        image = self.totensor(image)\n",
        "        return {\"low\":image.cuda(), \"high\":I.cuda()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DykaPSf3dRZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_ckpt(path):\n",
        "    epo = 0\n",
        "    ckpt_list = list(os.walk(path))[0][2]\n",
        "    for ckpt_file in ckpt_list:\n",
        "        if ckpt_file.endswith('.pt'):\n",
        "            ep = int(ckpt_file[:-3].split('-')[1])\n",
        "            if ep > epo:\n",
        "                epo = ep\n",
        "    return f'fsrcnn-{epo}.pt'\n",
        "\n",
        "def save_ckpt(path, model, optimizer, scheduler, epoch, step):\n",
        "    torch.save({\n",
        "        'epoch': epoch, \n",
        "        'step': step, \n",
        "        'model_state_dict': model.state_dict(), \n",
        "        'optimizer_state_dict': optimizer.state_dict(), \n",
        "        'scheduler_state_dict': scheduler.state_dict(), \n",
        "    }, os.path.join(path, f'fsrcnn-{epoch}.pt'))\n",
        "\n",
        "def load_ckpt(path, model, optimizer=None, scheduler=None, epoch=0):\n",
        "    if epoch > 0:\n",
        "        ckpt_file = f'fsrcnn-{epoch}.pt'\n",
        "    else:\n",
        "        ckpt_file = find_ckpt(path)\n",
        "    state = torch.load(os.path.join(path, ckpt_file))\n",
        "    model.load_state_dict(state['model_state_dict'])\n",
        "    if optimizer is not None:\n",
        "        optimizer.load_state_dict(state['optimizer_state_dict'])\n",
        "    if scheduler is not None:\n",
        "        scheduler.load_state_dict(state['scheduler_state_dict'])\n",
        "    return state['epoch'], state['step']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vtl2nQhthH81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SuperImage:\n",
        "    def __init__(self, gpu=True):\n",
        "        self.gpu = gpu\n",
        "\n",
        "    def __run(self, model, image):\n",
        "        model.eval()\n",
        "        image = image/255.\n",
        "        if self.gpu:\n",
        "            model.cuda()\n",
        "            image = image.cuda()\n",
        "        outp = model(image)\n",
        "        outp = torch.clamp(outp, 0., 1.)\n",
        "        outp = outp.detach().cpu().numpy().squeeze()\n",
        "        return (outp*255.).astype(np.uint8)\n",
        "    \n",
        "    def scale2x(self, model, image, median_blur=False):\n",
        "        if isinstance(image, str):\n",
        "            image = cv2.imread(image)\n",
        "        y, cr, cb = cv2.split(cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb))\n",
        "        h, w = y.shape\n",
        "        cr = cv2.resize(cr, (2*w,2*h), cv2.INTER_LANCZOS4)\n",
        "        cb = cv2.resize(cb, (2*w,2*h), cv2.INTER_LANCZOS4)\n",
        "        y = torch.from_numpy(y[np.newaxis,np.newaxis,:,:]).type(torch.FloatTensor)\n",
        "        outp = self.__run(model, y)\n",
        "        image2x = np.stack((outp, cr, cb), axis=2)\n",
        "        image2x = cv2.cvtColor(image2x, cv2.COLOR_YCrCb2BGR)\n",
        "        if median_blur:\n",
        "            image2x = cv2.medianBlur(image2x, 3)\n",
        "        return image2x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BYpgZeBR67s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training_loop(model, dataloader, path, lr1=1e-3, lr2=1e-4, epoch=100, resume=-1):\n",
        "    model.cuda()\n",
        "    mse = nn.MSELoss().cuda()\n",
        "    optimizer = optim.Adam([\n",
        "        {'params': model.first_part.parameters(), 'lr': lr1},\n",
        "        {'params': model.mid_part.parameters(), 'lr': lr1},\n",
        "        {'params': model.last_part.parameters(), 'lr': lr2},\n",
        "        {'params': model.smooth_part.parameters(), 'lr': lr2}\n",
        "    ])\n",
        "    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, 50, gamma=.1)\n",
        "    epo, batch = 0, 0\n",
        "    last_epoch_batch = 0\n",
        "    if resume >= 0:\n",
        "        epo, batch = load_ckpt(path, model, optimizer, lr_scheduler, epoch=resume)\n",
        "        print(f'restart after epoch {epo}')\n",
        "    solver = SuperImage()\n",
        "    print(f'model is training: {model.training}')\n",
        "    for ep in range(epo, epoch):\n",
        "        epoch_loss = 0.\n",
        "        lrs = [params['lr'] for params in optimizer.state_dict()['param_groups']]\n",
        "        for sample in dataloader:\n",
        "            inp = sample[\"low\"]\n",
        "            gt = sample[\"high\"]\n",
        "            model.train()\n",
        "            outp = model(inp)\n",
        "            outp = torch.clamp(outp, 0., 1.)\n",
        "            loss = mse(gt, outp)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss\n",
        "            batch += 1\n",
        "        lr_scheduler.step()\n",
        "        print(f\"Ep.{ep+1} - loss: {epoch_loss/(batch-last_epoch_batch):.6f} - lr: {lrs}\")\n",
        "        last_epoch_batch = batch\n",
        "        save_ckpt(path, model, optimizer, lr_scheduler, ep+1, batch)\n",
        "        print(f'Ep.{ep+1} - model saved')\n",
        "        cv2.imwrite(f'demo.png', solver.scale2x(model, 'demo_half.png'))\n",
        "        cv2.imwrite(f'train.png', solver.scale2x(model, 'data/img_1000.png'))\n",
        "        torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fbrU5aTR9df",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = SuperResolutionDataset('data')\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ3NpJzZwyRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fsrcnn = FSRCNN(1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsU608HBp4FP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_loop(fsrcnn, dataloader, 'drive/My Drive/checkpoints')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}